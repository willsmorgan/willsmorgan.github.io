<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>William Morgan on William Morgan</title>
    <link>/willsmorgan.github.io/</link>
    <description>Recent content in William Morgan on William Morgan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0700</lastBuildDate>
    <atom:link href="/willsmorgan.github.io/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Faculty Engagement in Online Discussion Forums</title>
      <link>/willsmorgan.github.io/project/2018-07-02-faculty-engagement-in-online-discussion-forums/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>/willsmorgan.github.io/project/2018-07-02-faculty-engagement-in-online-discussion-forums/</guid>
      <description>

&lt;p&gt;Forums are a common component of online courses. Generally, they are used a
medium for students and instructors to interact with one another for discussion,
inquiry, etc.&lt;/p&gt;

&lt;p&gt;Instructors generally use these forums to make announcements regarding due dates,
answer student questions and comment on student discussion. This project explored
how faculty engagement in these specific environments affected various student
outcomes. Specifically, we investigate its relationship with student forum activity
and student grades.&lt;/p&gt;

&lt;p&gt;This project had several other collaborators whose work may or may not be included
in this repository. The other collaborators who helped accomplish this project
were Phil Arcuria, Patrick Pettyjohn, and Mike Sharkey.&lt;/p&gt;

&lt;h3 id=&#34;project-highlights&#34;&gt;Project Highlights&lt;/h3&gt;

&lt;h4 id=&#34;types-of-engagement&#34;&gt;Types of Engagement&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Presence of a &lt;strong&gt;Hallway Conversation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;ldquo;Hallway Conversations&amp;rdquo; are instructor-led general discussion forums that are meant
  to replicate natural conversation that would take a place in a physical classroom&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Post Consistency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How consistently are instructors making posts? We do not make distinction between types of
  posts or in which forums these are taking place - only the variation in posts
  from week to week.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Post Quantity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The overall number of posts made by faculty and instructors in the course&lt;/p&gt;

&lt;h4 id=&#34;tested-outcomes&#34;&gt;Tested Outcomes&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Student Perception of Faculty Engagement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Students are given optional course evaluation surveys at the end of the semester. Three
  of the questions on the survey pertain to how the student percieves the faculty instruction
  of the course. Responses are given on a 5-point Likert scale, ranging from 1 (low) to 5 (high)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Student Posting Activity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The average number of posts per student in a given course&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Student Grades&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The average student grade received in a course-section, converted to a 4.33 numeric scale&lt;/p&gt;

&lt;h4 id=&#34;results&#34;&gt;Results&lt;/h4&gt;

&lt;p&gt;On the whole, faculty engagement in discussion forums seemed to have no significant impact
on any of the outcomes we examined. These results are somewhat counterintuitive, given that
faculty engagement is widely believed to be a key factor in student success.&lt;/p&gt;

&lt;p&gt;We believe there to be two reasonable explanations for this outcome. First, the scope was rather
narrow in regards to the possible ways faculty can engage with their students. The study was limited
to activity within discussion forums and may have excluded a variety of other methods of communication
like email, announcements, or in-person discussion. Second, we found evidence to suggest that much of the
activity on the forums came about simply because of unspoken institutional policy. Several instructional
designers confirmed that it is generally suggested to instructors to require students to make three
posts per week. We found that the majority of the course-sections had roughly 3 posts per student per week
for the duration of the course, suggesting that students might be posting simply in order
to meet a particular arbitrary requirement. Hypothetically, this could keep forums from being a place
for natural discussion and peer-to-peer learning.&lt;/p&gt;

&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;This project was meant to be a very preliminary exploration into faculty use of forums and their effect
on various student outcomes. From the surface it did not appear that there were any significant relationships
but it could certainly be the case that our operational definitions of engagement were too restrictive,
or that discussion forums simply aren&amp;rsquo;t being used the way we assumed they were. In either case,
there is still much to explore in this domain.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parallelizing Random Forests in R</title>
      <link>/willsmorgan.github.io/post/parallelizing-random-forests-in-r/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/parallelizing-random-forests-in-r/</guid>
      <description>&lt;p&gt;Recently I’ve been working on a project with the goal of understanding how students choose between course modalities (online or in-person). My goal so far has been to test a handful of models to come up with the most accurate way of predicting the likelihood that a student will take a course online. Hopefully, this best-performing model would offer some interpretability so that I can see which variables offer the most predictive power.&lt;/p&gt;
&lt;p&gt;In working through this problem it has become necessary for me to take advantage of parallel processing so I can actually get results in a reasonable amount of time. &lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/index.html&#34;&gt;&lt;code&gt;glmnet&lt;/code&gt;&lt;/a&gt; offers in-house parallel processing, so for penalized regression it has been a breeze. On the other hand, I haven’t found a native implementation in &lt;a href=&#34;https://cran.r-project.org/package=randomForest&#34;&gt;&lt;code&gt;randomForest&lt;/code&gt;&lt;/a&gt; so I thought it might be a good exercise to create one myself and make a post about it in case there are others that run into the same problem.&lt;/p&gt;
&lt;p&gt;I use several packages to accomplish this task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;doParallel&lt;/code&gt;, &lt;code&gt;foreach&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;The workhorse behind the parallel processing&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;caret&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Not explicitly called on in this example, but I do use it in my other work to define folds for cross-validation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;randomForest&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Used for creating the trees&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is only a little more than 50 lines of code in the example, but there is a good amount to dissect. First, it should be noted that the size of the tree must be specified a priori - the main goal is to get an estimate of the out-of-sample error for a particular forest size (i.e. a specific hyperparameter value). The function starts by iterating through each of the K folds of your data. For a given fold, the tree-growing is done in ten separate groups and then combined. In other words, for a random forest with 100 trees, we grow ten forests of ten trees and combine them using &lt;code&gt;randomForest::combine&lt;/code&gt; (this decision about ten groups is completely arbitrary, I just assumed that any forest size I was going to test would be divisible by ten). This function is absolutely critical and is the key reason we can use &lt;code&gt;%dopar%&lt;/code&gt; here. Once the random forest is put back together, we estimate the out-of-sample error and move on to the next fold. Finally, the results are averaged across all K folds and the function spits out a data frame detailing the number of trees that were grown and the misclassification rate.&lt;/p&gt;
&lt;p&gt;This function isn’t perfect, but it certainly does the trick. It’d be nice to include some other forms of error on top of the misclassification rate and allow for many forest sizes to be tested. For now, I’ll keep this in my back pocket and robustify it in the future.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cvRF &amp;lt;- function(X, Y, ntrees, folds, parallel = TRUE) {
  &amp;#39;
  Use foreach to parallelize RF tree growth for a specified number of trees and
  estimate OOB error using cross-validation
  
  Args:
  - X --&amp;gt; matrix of predictors
  - Y --&amp;gt; vector/factor of responses
  - ntrees --&amp;gt; numeric value for size of forest
  - folds ---&amp;gt; vector of integers with length equal to number of rows in X/Y
  - parallel ---&amp;gt; boolean for using parallel 

  Returns:
  - df with two columns:
  - num_trees
  - misclassification rate
  &amp;#39;
  
  # Initiate cluster
  if (parallel) {
    cl &amp;lt;- makeCluster(detectCores() - 2)
    registerDoParallel(cl)
  }
  
  cat(&amp;quot;Testing RF of size:&amp;quot;, ntrees, &amp;quot;\n&amp;quot;)
  
  # Begin CV
  result &amp;lt;- foreach(j = 1:max(folds), .combine = bind_rows) %do% {
    
    cat(&amp;quot;Fold&amp;quot;, j, &amp;quot;of&amp;quot;, max(folds), &amp;quot;\n&amp;quot;)
    
    # Grow trees in parallel and combine into one
    rf &amp;lt;- foreach(ntree = rep(ntrees/10, 10), .combine = combine, .packages = &amp;#39;randomForest&amp;#39;) %dopar% {
      
      # Grow indvl tree on the k-1 folds
      randomForest(
        x = X[folds != j, ],
        y = Y[folds != j],
        ntree = ntree,
        mtry = sqrt(dim(X)[2])
      )
    }
    
    # Predict on out-of-sample fold
    pred &amp;lt;- predict(rf, X[folds == j, ], type = &amp;#39;response&amp;#39;)
    
    # Return df of results
    data.frame(
      num_trees = ntrees,
      misclassification = 1 - mean(pred == Y[folds == j]),
      fold = j
    )
  }
  
  # Stop cluster
  if (parallel) {on.exit(stopCluster(cl))}
  
  # Average error rate across folds
  result %&amp;lt;&amp;gt;% group_by(num_trees) %&amp;gt;% summarise_at(vars(misclassification), mean)
  
  return(result)
}&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Practice Post</title>
      <link>/willsmorgan.github.io/post/practice-post/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/practice-post/</guid>
      <description>&lt;p&gt;My name is Will Morgan and this is a test post&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>/willsmorgan.github.io/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      
      <guid>/willsmorgan.github.io/project/deep-learning/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/willsmorgan.github.io/project/example-external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      
      <guid>/willsmorgan.github.io/project/example-external-project/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
