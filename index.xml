<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>William Morgan on William Morgan</title>
    <link>/willsmorgan.github.io/</link>
    <description>Recent content in William Morgan on William Morgan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0700</lastBuildDate>
    <atom:link href="/willsmorgan.github.io/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Book Discussion - Mostly Harmless Econometrics: Chapter 1</title>
      <link>/willsmorgan.github.io/post/book-discussion-mostly-harmless-econometrics-chapter-1/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/book-discussion-mostly-harmless-econometrics-chapter-1/</guid>
      <description>

&lt;h4 id=&#34;motivation&#34;&gt;Motivation&lt;/h4&gt;

&lt;p&gt;This will be part of a series of posts I am writing to help bring my chops on causal
inference up to par. Since I have not taken a formal course on the subject and I won&amp;rsquo;t be
able to for some time, self-study is my only option. Fortunately I&amp;rsquo;ve been recommended
quite a few resources from my instructors, one of which being
&lt;strong&gt;Mostly Harmless Econometrics&lt;/strong&gt; by Joshua D. Angrist &amp;amp; Jorn-Steffen Pischke,
econometricians at MIT and LSE respectively.&lt;/p&gt;

&lt;p&gt;This and the next handful of posts will be discussions about topics covered throughout
the book, including short summaries, descriptions of my understanding of the concepts,
and potential applications to my own work.&lt;/p&gt;

&lt;h4 id=&#34;chapter-1-questions-about-questions&#34;&gt;Chapter 1: Questions about &lt;em&gt;Questions&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;At the Action Lab there is practically an immeasurable variety of data available
to us researchers. We have student data, institutional data, clickstream data,
and all other sorts of data that has been collected for years and years. When I was
dumped into this massive environment as a fresh student worker I was
hopping around from one thing to the next, searching for ways to implement everything
I had learned in class and hoping to find great insights everywhere I went. As any
experienced researcher would expect, this ended up wasting a lot of time. I wrote
tons of cleaning and modeling scripts for projects that eventually were
thrown into the &amp;ldquo;revisit this&amp;rdquo; folder of my hard drive, never to be touched again.&lt;/p&gt;

&lt;p&gt;The lack of direction in my research was keeping me from accomplishing anything. I was constantly
getting ahead of myself, imagining the shiny new models I could implement and the fantastic
results I could expect instead of nailing down a specific research agenda. A much more pragmatic
approach would have been to follow the strategy offered by Angrist and Pischke in their opening
chapter, &lt;strong&gt;Questions about Questions&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The FAQs as they call them, are the four research questions econometricians
should ask themselves before embarking on a new project:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;What is the causal relationship of interest?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is the ideal experiment that would identify this causal effect?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is the identification strategy?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is the mode of statistical inference?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first question is pretty straightforward, or at least it should be - it
is the foundation of the entire project. Nonetheless, it is important
to explicitly identify the relationship you want to investigate. Doing so will be helpful in several ways
as the project matures. First, it will help give you a sense
of your data necessities. If you are interested in changes in employment outcomes
as a result of successfully completing MOOCs, you should be considering
the types of outcomes that are observable and their availability to the public.
Second, knowing the type of relationship you&amp;rsquo;re trying
to measure will inform your methodology. A relationship that is temporal in nature
will likely call for some sort of time series model, or maybe the effect
only manifests in extreme scenarios, in which case subsampling might be of interest.&lt;/p&gt;

&lt;p&gt;Our second question is slightly more abstract than the first but still important in
designing the overall agenda. In the event that you end up with a limitless budget and no higher authority questioning
your ethics, what&amp;rsquo;d be the best scenario for observing the effect you are interested in?
Your answer doesn&amp;rsquo;t have to be feasible, but it does have to be realistic. The point of this
question is to force you to consider all possible mechanisms to be changed or held constant in order to observe
the effect you&amp;rsquo;re after. The secondary purpose of this question is to help you reveal potential
flaws with the overall goal of the research. Questions that cannot be answered
by any sort of experimental design are what Angrist and Pischke call FUQ&amp;rsquo;d:
Fundamentally Unanswered Questions.&lt;/p&gt;

&lt;p&gt;Our two final questions are concerned with the specific data and methodological needs
to carry out a study. Often it is the case in economics (and social sciences more generally)
that experimentation is not feasible because of cost or ethical concerns. Observational data
then becomes the stand-in for data generated by a randomized trial, so it is crucial for
researchers to understand how to use that data in order to simulate a real experiment.
This technique, as the authors define it, is the &lt;em&gt;identification strategy&lt;/em&gt;. The mode of statistical
inference is closely related to a researcher&amp;rsquo;s identification strategy. It defines the population
of interest, the type of sample that is collected, and the various modeling assumptions that
have to be made in order to extract reasonable, well-constructed results. This will be the most
technically demanding portion of the project and the integrity of the results will rely almost
entirely on the correct execution of your statistics.&lt;/p&gt;

&lt;p&gt;The answers to these FAQs should outline very clearly a researcher&amp;rsquo;s entire project agenda.
Without answering these, a straightforward project can quickly derail and turn into
a sloppy mess of misguided intentions and no clear end. In any case, this opening chapter
of &lt;em&gt;Mostly Harmless Econometrics&lt;/em&gt; has made me reconsider how I approach the research I want
to conduct and will hopefully make me a more pragmatic and efficacious student of economics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Faculty Engagement in Online Discussion Forums</title>
      <link>/willsmorgan.github.io/project/2018-07-02-faculty-engagement-in-online-discussion-forums/</link>
      <pubDate>Mon, 02 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>/willsmorgan.github.io/project/2018-07-02-faculty-engagement-in-online-discussion-forums/</guid>
      <description>

&lt;p&gt;Forums are a common component of online courses. Generally, they are used a
medium for students and instructors to interact with one another for discussion,
inquiry, etc.&lt;/p&gt;

&lt;p&gt;Instructors generally use these forums to make announcements regarding due dates,
answer student questions and comment on student discussion. This project explored
how faculty engagement in these specific environments affected various student
outcomes. Specifically, we investigate its relationship with student forum activity
and student grades.&lt;/p&gt;

&lt;p&gt;This project had several other collaborators whose work may or may not be included
in this repository. The other collaborators who helped accomplish this project
were Phil Arcuria, Patrick Pettyjohn, and Mike Sharkey.&lt;/p&gt;

&lt;h3 id=&#34;project-highlights&#34;&gt;Project Highlights&lt;/h3&gt;

&lt;h4 id=&#34;types-of-engagement&#34;&gt;Types of Engagement&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Presence of a &lt;strong&gt;Hallway Conversation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;ldquo;Hallway Conversations&amp;rdquo; are instructor-led general discussion forums that are meant
  to replicate natural conversation that would take a place in a physical classroom&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Post Consistency&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How consistently are instructors making posts? We do not make distinction between types of
  posts or in which forums these are taking place - only the variation in posts
  from week to week.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Post Quantity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The overall number of posts made by faculty and instructors in the course&lt;/p&gt;

&lt;h4 id=&#34;tested-outcomes&#34;&gt;Tested Outcomes&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Student Perception of Faculty Engagement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Students are given optional course evaluation surveys at the end of the semester. Three
  of the questions on the survey pertain to how the student percieves the faculty instruction
  of the course. Responses are given on a 5-point Likert scale, ranging from 1 (low) to 5 (high)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Student Posting Activity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The average number of posts per student in a given course&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Student Grades&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The average student grade received in a course-section, converted to a 4.33 numeric scale&lt;/p&gt;

&lt;h4 id=&#34;results&#34;&gt;Results&lt;/h4&gt;

&lt;p&gt;On the whole, faculty engagement in discussion forums seemed to have no significant impact
on any of the outcomes we examined. These results are somewhat counterintuitive, given that
faculty engagement is widely believed to be a key factor in student success.&lt;/p&gt;

&lt;p&gt;We believe there to be two reasonable explanations for this outcome. First, the scope was rather
narrow in regards to the possible ways faculty can engage with their students. The study was limited
to activity within discussion forums and may have excluded a variety of other methods of communication
like email, announcements, or in-person discussion. Second, we found evidence to suggest that much of the
activity on the forums came about simply because of unspoken institutional policy. Several instructional
designers confirmed that it is generally suggested to instructors to require students to make three
posts per week. We found that the majority of the course-sections had roughly 3 posts per student per week
for the duration of the course, suggesting that students might be posting simply in order
to meet a particular arbitrary requirement. Hypothetically, this could keep forums from being a place
for natural discussion and peer-to-peer learning.&lt;/p&gt;

&lt;h4 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;This project was meant to be a very preliminary exploration into faculty use of forums and their effect
on various student outcomes. From the surface it did not appear that there were any significant relationships
but it could certainly be the case that our operational definitions of engagement were too restrictive,
or that discussion forums simply aren&amp;rsquo;t being used the way we assumed they were. In either case,
there is still much to explore in this domain.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parallelizing Random Forests in R</title>
      <link>/willsmorgan.github.io/post/parallelizing-random-forests-in-r/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/parallelizing-random-forests-in-r/</guid>
      <description>&lt;p&gt;Recently I’ve been working on a project with the goal of understanding how students choose between course modalities (online or in-person). My goal so far has been to test a handful of models to come up with the most accurate way of predicting the likelihood that a student will take a course online. Hopefully, this best-performing model would offer some interpretability so that I can see which variables offer the most predictive power.&lt;/p&gt;
&lt;p&gt;In working through this problem it has become necessary for me to take advantage of parallel processing so I can actually get results in a reasonable amount of time. &lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/index.html&#34;&gt;&lt;code&gt;glmnet&lt;/code&gt;&lt;/a&gt; offers in-house parallel processing, so for penalized regression it has been a breeze. On the other hand, I haven’t found a native implementation in &lt;a href=&#34;https://cran.r-project.org/package=randomForest&#34;&gt;&lt;code&gt;randomForest&lt;/code&gt;&lt;/a&gt; so I thought it might be a good exercise to create one myself and make a post about it in case there are others that run into the same problem.&lt;/p&gt;
&lt;p&gt;I use several packages to accomplish this task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;doParallel&lt;/code&gt;, &lt;code&gt;foreach&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;The workhorse behind the parallel processing&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;caret&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Not explicitly called on in this example, but I do use it in my other work to define folds for cross-validation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;randomForest&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Used for creating the trees&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is only a little more than 50 lines of code in the example, but there is a good amount to dissect. First, it should be noted that the size of the tree must be specified a priori - the main goal is to get an estimate of the out-of-sample error for a particular forest size (i.e. a specific hyperparameter value). The function starts by iterating through each of the K folds of your data. For a given fold, the tree-growing is done in ten separate groups and then combined. In other words, for a random forest with 100 trees, we grow ten forests of ten trees and combine them using &lt;code&gt;randomForest::combine&lt;/code&gt; (this decision about ten groups is completely arbitrary, I just assumed that any forest size I was going to test would be divisible by ten). This function is absolutely critical and is the key reason we can use &lt;code&gt;%dopar%&lt;/code&gt; here. Once the random forest is put back together, we estimate the out-of-sample error and move on to the next fold. Finally, the results are averaged across all K folds and the function spits out a data frame detailing the number of trees that were grown and the misclassification rate.&lt;/p&gt;
&lt;p&gt;This function isn’t perfect, but it certainly does the trick. It’d be nice to include some other forms of error on top of the misclassification rate and allow for many forest sizes to be tested. For now, I’ll keep this in my back pocket and robustify it in the future.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cvRF &amp;lt;- function(X, Y, ntrees, folds, parallel = TRUE) {
  &amp;#39;
  Use foreach to parallelize RF tree growth for a specified number of trees and
  estimate OOB error using cross-validation
  
  Args:
  - X --&amp;gt; matrix of predictors
  - Y --&amp;gt; vector/factor of responses
  - ntrees --&amp;gt; numeric value for size of forest
  - folds ---&amp;gt; vector of integers with length equal to number of rows in X/Y
  - parallel ---&amp;gt; boolean for using parallel 

  Returns:
  - df with two columns:
  - num_trees
  - misclassification rate
  &amp;#39;
  
  # Initiate cluster
  if (parallel) {
    cl &amp;lt;- makeCluster(detectCores() - 2)
    registerDoParallel(cl)
  }
  
  cat(&amp;quot;Testing RF of size:&amp;quot;, ntrees, &amp;quot;\n&amp;quot;)
  
  # Begin CV
  result &amp;lt;- foreach(j = 1:max(folds), .combine = bind_rows) %do% {
    
    cat(&amp;quot;Fold&amp;quot;, j, &amp;quot;of&amp;quot;, max(folds), &amp;quot;\n&amp;quot;)
    
    # Grow trees in parallel and combine into one
    rf &amp;lt;- foreach(ntree = rep(ntrees/10, 10), .combine = combine, .packages = &amp;#39;randomForest&amp;#39;) %dopar% {
      
      # Grow indvl tree on the k-1 folds
      randomForest(
        x = X[folds != j, ],
        y = Y[folds != j],
        ntree = ntree,
        mtry = sqrt(dim(X)[2])
      )
    }
    
    # Predict on out-of-sample fold
    pred &amp;lt;- predict(rf, X[folds == j, ], type = &amp;#39;response&amp;#39;)
    
    # Return df of results
    data.frame(
      num_trees = ntrees,
      misclassification = 1 - mean(pred == Y[folds == j]),
      fold = j
    )
  }
  
  # Stop cluster
  if (parallel) {on.exit(stopCluster(cl))}
  
  # Average error rate across folds
  result %&amp;lt;&amp;gt;% group_by(num_trees) %&amp;gt;% summarise_at(vars(misclassification), mean)
  
  return(result)
}&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
