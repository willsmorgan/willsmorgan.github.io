<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>William Morgan on William Morgan</title>
    <link>/willsmorgan.github.io/</link>
    <description>Recent content in William Morgan on William Morgan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 -0700</lastBuildDate>
    <atom:link href="/willsmorgan.github.io/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Solving Collinearity with Penalized Regression</title>
      <link>/willsmorgan.github.io/post/solving-collinearity-with-penalized-regression/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/solving-collinearity-with-penalized-regression/</guid>
      <description>&lt;div id=&#34;motivation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;One of my colleagues has been working on a project analysing a particular type of student survey data. The data is partitioned into a handful of sub-surveys measuring (essentially) different categorizations of non-cognitive skills and personality/learning traits. One aim of the project was to evaluate how combinations of metrics from the individual tests could be used to predict student outcomes. There were over 100 variables he was intending to analyze, many of which had seemingly overlapping definitions, so collinearity was a big concern going into it. To get around the problem, this researcher chose to use penalized linear regression, claiming that it “solved” the problem of multicollinearity. I wasn’t familiar enough with the mechanics of the technique, so I decided to investigate more and find out what was going on underneath the hood.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-multicollinearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is (multi)collinearity?&lt;/h2&gt;
&lt;p&gt;In layman’s terms, collinearity occurs when some of the information being used to make predictions on a particular outcome is redundant. For example, say I tell you to predict a person’s wage given the number of years of education they have and their highest achieved degree. Although they aren’t exactly the same, you could almost perfectly predict their highest achieved degree by checking the number of years they’ve been in school. A person who’s completed 12 years of education is likely to only have their high school diploma, someone with 16 years will probably have their undergraduate degree, and so on. This situation doesn’t exemplify &lt;strong&gt;perfect&lt;/strong&gt; collinearity, but the fact that these two bits of information are highly correlated can cause problems in linear regression. Likewise, multicollinearity can be thought of in the same way - redundant information. It is slightly more difficult to identify, but the idea is the same. Multicollinearity occurs when one variable can be explained by a combination of other variables.&lt;/p&gt;
&lt;p&gt;Mathematically, perfect collinearity is defined as two variables &lt;span class=&#34;math inline&#34;&gt;\(X_1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_2\)&lt;/span&gt; having an exactly linear relationship. That is, there exist two scalars &lt;span class=&#34;math inline&#34;&gt;\(a_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(a_1\)&lt;/span&gt;, at least one nonzero, such that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X_2 = a_0 + a_1X_1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For reasons I’ll show later, we aren’t necessarily worried about &lt;em&gt;perfect&lt;/em&gt; collinearity - the more common scenario is &lt;em&gt;near-perfect&lt;/em&gt; collinearity. This definition is actually just an application of linear dependence, so the more general definition can just be rephrased as such - collinearity is defined as the existence of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; constants &lt;span class=&#34;math inline&#34;&gt;\(a_1,\dotsb, a_p\)&lt;/span&gt;, not all zero, such that &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^p a_iX_i = 0\)&lt;/span&gt;. In matrix notation,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\boldsymbol{X}\boldsymbol{a} = \boldsymbol{0}\]&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{a}\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\(p \times 1\)&lt;/span&gt; vector with at least one nonzero entry and &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{X}\)&lt;/span&gt; is the &lt;span class=&#34;math inline&#34;&gt;\(n \times p\)&lt;/span&gt; model matrix.&lt;/p&gt;
&lt;p&gt;As you can imagine, checking for collinearity can be as simple as looking for perfect correlation. Multicollinearity is not as simple, but many choose to look at the Variance Inflation Factor (VIF). I won’t go into further detail here, but VIF is essentially a measure of how much one variable is explained by the rest of the variables in your data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effects-of-multicollinearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Effects of Multicollinearity&lt;/h2&gt;
&lt;p&gt;In the general sense, presence of multicollinearity can impact the validity of our parameter estimates. Theoretically it can keep us from finding a unique set of solutions, but more often the worry is about the variance (and standard error) of the estimates. In particular, recall the solution to the standard multiple regression problem:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\beta} = (\boldsymbol{X}^{T}\boldsymbol{X})^{-1}\boldsymbol{X}^{T}\boldsymbol{y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;First of all, for there be a unique solution for &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}\)&lt;/span&gt; we need to guarantee that &lt;span class=&#34;math inline&#34;&gt;\((\boldsymbol{X}^{T}\boldsymbol{X})\)&lt;/span&gt; is invertible. When &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; has linearly dependent columns, then there exists a vector &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{a}\)&lt;/span&gt; (not all zero) such that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\boldsymbol{X}\boldsymbol{a} = 0\]&lt;/span&gt; If this is the case, then:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\|\boldsymbol{X}\boldsymbol{a}\|_2^{2} = \boldsymbol{a}^{T}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{a} = 0\]&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;and since &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{a}\)&lt;/span&gt; is a nonzero vector, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{X}^{T}\boldsymbol{X}\)&lt;/span&gt; is not positive definite. Hence, &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{X}^{T}\boldsymbol{X}\)&lt;/span&gt; is not invertible.&lt;/p&gt;
&lt;p&gt;In the case that our predictors are &lt;strong&gt;nearly&lt;/strong&gt; collinear the matrix will still have an inverse, but the entries in that matrix will be massive. This is worrisome when we consider the equation for the variance of the estimates:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Var[\hat{\beta}] = \boldsymbol{\sigma^2}(\boldsymbol{X}^{T}\boldsymbol{X})^{-1}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As this value increases the precision of our estimates worsen, making us far less certain about the range of possible values each estimate can take on. To illustrate, I’ll create a 3-column matrix, where the first two columns are random pulls from the standard normal distribution and the third column is a linear combination of the first two.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(18)

### Create (almost) collinear matrix
x1 &amp;lt;- rnorm(10000)
x2 &amp;lt;- rnorm(10000)
x3 &amp;lt;- 3*x1 + 4*x2 + rnorm(10000, sd = 0.0001)        # add a teeny bit of noise

X1 = matrix(c(x1, x2, x3), nrow = 10000) 

# Check for large values
solve(t(X1) %*% X1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]      [,2]       [,3]
## [1,]  88747.42 118329.88 -29582.469
## [2,] 118329.88 157773.15 -39443.288
## [3,] -29582.47 -39443.29   9860.822&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;penalized-regression-and-collinearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Penalized Regression and Collinearity&lt;/h2&gt;
&lt;p&gt;Now that we understand the impact of collinearity, we can easily see how penalized regression addressess the issue. First, let’s first observe the solution the ridge regression problem (the results are the same for lasso regression):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{\beta} = (\boldsymbol{X}^{T}\boldsymbol{X} + \lambda I)^{-1}\boldsymbol{X}^{T}\boldsymbol{y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are primarily concerned about finding that inverse - how do we know that the inverse exists, even when &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{X}^{T}\boldsymbol{X}\)&lt;/span&gt; is not? We’ll use same method used above to prove the invertibility - by checking if the matrix is positive definite. First, let &lt;span class=&#34;math inline&#34;&gt;\(\boldsymbol{a}\)&lt;/span&gt; be any nonzero vector of length &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;. Then, observe that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \boldsymbol{a}^{T}(\boldsymbol{X}^{T}\boldsymbol{X} + \lambda I)\boldsymbol{a}\\
  = \boldsymbol{a}^{T}\boldsymbol{X}^{T}\boldsymbol{X}\boldsymbol{a} + \boldsymbol{a}^{T}\lambda I\boldsymbol{a} \\
  = 0 + \lambda \boldsymbol{a}^{T}\boldsymbol{a} \\
  = \lambda \|\boldsymbol{a}\|_2^{2}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Both terms are positive, so &lt;span class=&#34;math inline&#34;&gt;\(\lambda \|\boldsymbol{a}\|_2^{2} &amp;gt; 0\)&lt;/span&gt;, implying that the matrix is positive definite and hence invertible. This solves our first problem with the uniqueness of solutions. We now need to see how this affects the size of the values in the inverted matrix to verify if it decreases the variance.&lt;/p&gt;
&lt;p&gt;I’ll begin by taking the Frobenius norm of the inverse when &lt;span class=&#34;math inline&#34;&gt;\(\lambda = 0\)&lt;/span&gt; to get a sense of the magnitude of the values in the original matrix. Then, I’ll test a sequence of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; values to see how the norm changes as the penalty is increased. This isn’t the most formal test, but it will at least make clear how the inverse matrix changes (and hence the variance of the estimates) in &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lambda &amp;lt;-  seq(0, 100,  by = 1)

norms &amp;lt;- vector(mode = &amp;#39;numeric&amp;#39;, length = 101)
for (i in seq_along(lambda)) {
  norms[i] &amp;lt;- Matrix::norm(solve(t(X1) %*% X1 + lambda[i]*diag(3)))
}

data.frame(penalty = lambda, matrix_norm = norms) %&amp;gt;%
  ggplot(., aes(penalty, log(matrix_norm))) + 
  geom_line() + 
  labs(title = &amp;quot;Matrix norm as a function of Lambda&amp;quot;) + 
  theme(plot.title = element_text(hjust = 0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/willsmorgan.github.io/willsmorgan.github.io/post/2018-09-03-solving-collinearity-with-penalized-regression_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, the regularization has a huge effect on the norm of the matrix - I even had to log the norm to make the graph more readable (otherwise it’d look like an L and wouldn’t be that interesting). This is the result we were looking for - the penalty helps keep down the variance of the estimates. This shouldn’t be terribly surprising, as that is the exact purpose of this technique. Ridge and lasso regression intentionally bias the coefficient estimates toward zero in order to shrink their variance for more generalizable results - it just so happens that it also solves the issue of collinearity.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;takeaways&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Takeaways&lt;/h2&gt;
&lt;p&gt;Theoretically, multicollinearity can be a pretty nasty issue. It gives us an infinite amount of solutions for the parameter estimates, basically shutting down the entire problem. Practically speaking, perfect multicollinearity will almost never happen unless you have some sort of redundant coding scheme in your categorical variables (which is part of the reason why you have to leave one level out as your “base” level). When the issue does arise, it will most likely be a case of near-perfect multicollinearity. This also has some worrisome effects on our estimates, as their standard errors start to blow up, widening the confidence intervals. Penalized regression fortunately does not suffer from this because of the nature of the solutions. That is not to say however that penalized regression is meant to be used as a solution to the multicollinearity problem - it is intended more for walking the bias-variance tradeoff. If you do happen to end up with a dataset suffering from multicollinearity, you should be doing some serious inspection on the individual variables instead of jumping immediately to penalized regression.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sources:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/lecture-17.pdf&#34;&gt;Lecture Notes&lt;/a&gt; from CMU’s Cosma Shalizi&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Daniel Seita’s &lt;a href=&#34;https://danieltakeshi.github.io/2016/08/05/a-useful-matrix-inverse-equality-for-ridge-regression/&#34;&gt;blog post&lt;/a&gt; on Ridge Regression inequalities&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.math.harvard.edu/archive/20_spring_05/handouts/ch05_notes.pdf&#34;&gt;More Lecture Notes&lt;/a&gt; from a Harvard Math 20 section on eigenstuffs&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Book Discussion - Mostly Harmless Econometrics: Chapter 2</title>
      <link>/willsmorgan.github.io/post/book-discussion-mostly-harmless-econometrics-chapter-2/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/book-discussion-mostly-harmless-econometrics-chapter-2/</guid>
      <description>&lt;div id=&#34;chapter-2-the-experimental-ideal&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Chapter 2: The Experimental Ideal&lt;/h4&gt;
&lt;p&gt;Angrist and Pischke begin building the foundation for concepts fundamental to causal inference in the second chapter of &lt;em&gt;Mostly Harmless Econometrics&lt;/em&gt;. It opens with an anecdote about a 1962 experiment conducted to assess the effects of an early-intervention in preschoolers, highlighting the project’s excellent randomized design. The study itself was used as evidence for the creation of the Head Start preschool program but for us it matters because it reflects the value of random assignment in research design. Without it, teasing out causal effects becomes a bit more involved. Namely, selection bias starts to creep in and distort our perception of the effect. There are other problems associated with non-random treatment assignment, but this is the largest barrier for proper inference.&lt;/p&gt;
&lt;p&gt;The rest of this chapter proceeds by describing first the nature of selection bias in the potential outcomes framework, then the random assignment solution to selection bias, and finally an introduction to analysis in a regression setting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-selection-bias&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2.1: What is Selection Bias?&lt;/h4&gt;
&lt;p&gt;Before defining selection bias formally we’ll begin with an example. Suppose I am interested in potential differences in student performance between online and in-person modalities for a given course. In other words, does a student perform better in the same course if they take it online (as opposed to in-person)? Here, the treatment is course modality and the outcome I’m interested in is the student’s grade. A naive approach would be to simply test for a difference in the mean grade received in each modality, so let’s begin there:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(dt[dt$modality == &amp;quot;Online&amp;quot;, &amp;quot;cgrade&amp;quot;],
       dt[dt$modality == &amp;quot;In-person&amp;quot;, &amp;quot;cgrade&amp;quot;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  dt[dt$modality == &amp;quot;Online&amp;quot;, &amp;quot;cgrade&amp;quot;] and dt[dt$modality == &amp;quot;In-person&amp;quot;, &amp;quot;cgrade&amp;quot;]
## t = -36.788, df = 13877, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.5008225 -0.4501533
## sample estimates:
## mean of x mean of y 
##  2.771123  3.246611&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There appears to be a significant difference between the two groups of ~0.5 grade points, which translates to about half a letter grade. It’s tempting to conclude that the online modality is less efficacious for students, but can we say that this difference is explained entirely by modality? It could certainly be the case that the proportion of students that are employed is much higher in the online population, decreasing the amount of available time they have for coursework. This could explain some of the variation in grades between the two groups that is not caused by the choice of modality.&lt;/p&gt;
&lt;p&gt;This hidden variation exactly captures the idea behind selection bias. The treatment assignment of having taking the course online is not distributed randomly among the entire population of students. The bias is introduced when certain subsets of the population (older, employed) are more likely to receive the treatment. In our example, the “estimate” of the causal effect is biased downwards for the reasons described previously.&lt;/p&gt;
&lt;p&gt;Now that we have a general understanding of the problem we can formalize the idea. However, before we get to the definition we’ll have to introduce the idea of &lt;em&gt;potential outcomes&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;potential-outcomes&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Potential Outcomes&lt;/h5&gt;
&lt;p&gt;Let’s continue with the above example - the online modality treatment. We can describe the treatment as a binary variable &lt;span class=&#34;math inline&#34;&gt;\(D_i = \{0,1\}\)&lt;/span&gt; and our outcome, grade points, as &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;. The basic question we’re interested in is whether &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt; differs depending on the presence or absence of &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;. For a given individual there will be two possible outcomes - the outcome had the student taken the course in-person or if they had taken it online. More specifically, we write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
  Y_i =
    \begin{cases}
      Y_{1i} &amp;amp; D_i = 1\\
      Y_{0i} &amp;amp; D_i = 0
    \end{cases}       
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this setup, the difference between &lt;span class=&#34;math inline&#34;&gt;\(Y_{1i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y_{0i}\)&lt;/span&gt; represents the causal effect of the treatment. This seems pretty obvious, but we’ve already run into one of the fundamental issues with causal inference: we never observe both potential outcomes. Instead, all can we can do is approximate the effect by looking at population outcomes. In particular, we hope to find the observed average difference in health&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
E[Y_i|D_i = 1] - E[Y_i|D_i = 0]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This can be conveniently rewritten in terms of our potential outcomes:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
= (E[Y_{1i}|D_i = 1] - E[Y_{0i}|D_i = 1]) + (E[Y_{0i}|D_i = 1] - E[Y_{0i}|D_i = 0])
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The term in the first set of parentheses is referred to as the &lt;em&gt;average treatment effect on the treated&lt;/em&gt;. In this case it represents what the average change in grades would be if the online students had taken their course in person. Likewise, the expression in the second set of parentheses represents the &lt;em&gt;selection bias&lt;/em&gt;. It describes the difference in average &lt;span class=&#34;math inline&#34;&gt;\(Y_{0i}\)&lt;/span&gt; between those who did and did not take a course online.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;solving-the-selection-problem&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2.2 Solving the selection problem&lt;/h4&gt;
&lt;p&gt;Angrist and Pischke put it very succinctly - “random assignment of &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; solves the selection problem because random assignment makes &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; independent of the potential outcomes” (p. 12). Notice that the selection bias term in the previous equation drops off when we substitute &lt;span class=&#34;math inline&#34;&gt;\(E[Y_{0i}|D_i = 0]\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(E[Y_{0i}|D_i = 1]\)&lt;/span&gt; (this is allowed because of the independence). We can take this simplification one step further and write our working equation as such:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
E[Y_{1i}|D_i = 1] - E[Y_{0i}|D_i = 1] = E[Y_{1i} - Y_{0i}|D_i = 1]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
= E[Y_{1i} - Y_{0i}]
\]&lt;/span&gt; This effectively means that the average treatment effect on the treated is equivalent to the average difference in potential outcomes of a randomly chosen subject. This is a easy simplification to read, but the more important outcome of random assignment is the elimination of the selection bias.&lt;/p&gt;
&lt;p&gt;One thing to note about random assignment is that the likelihood of treatment is not necessarily uniform over the entire population. In order to make a true apples-to-apples comparison, the likelihood of treatment needs to be uniform &lt;em&gt;conditional on subject characteristics&lt;/em&gt;. That is, subjects with similar characteristics like age, gender, academic ability, etc. must be equally likely to receive treatment. Another way to state this is that distributions of subject characteristics across treatment groups should be as similar as possible. It is common to verify this in a preliminary analysis to make sure the assumption of random selection holds water.&lt;/p&gt;
&lt;p&gt;Getting back to our earlier example, let’s check out the conditional distributions of some of the demographics of our data - we should expect to see roughly the same conditional means if the assumption of random assignment is correct.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   modality  age_at_class_start cgrade  male underrep
##   &amp;lt;chr&amp;gt;                  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 In-person               19.3   3.25 0.510    0.659
## 2 Online                  28.4   2.77 0.426    0.706&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on this table it is clear that the treatment in this data set is unlikely to be randomly assigned. The significant differences in age and other variables might be attributing to the observed differences in grade, so the initial comparison we made is almost certainly inappropriate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;regression&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2.3: Regression&lt;/h4&gt;
&lt;p&gt;Recall our original definition for the potential outcomes of observation &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
  Y_i =
    \begin{cases}
      Y_{1i} &amp;amp; D_i = 1\\
      Y_{0i} &amp;amp; D_i = 0
    \end{cases}       
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that we can rewrite this statement in a slightly more compact way:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y_i = Y_{0i} + (Y_{1i} - Y_{0i})D_i
\]&lt;/span&gt; Now, suppose the causal effect is fixed for the entire population. That is, assume &lt;span class=&#34;math inline&#34;&gt;\(Y_{1i} - Y_{0i} = \beta\)&lt;/span&gt;, some constant. (Sidebar - I switch up the notation found in the actual text to keep it somewhat in line with regression notation I am familiar with). With this assumption, we can now rewrite the above equation as such:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
= \alpha + \beta{D_i} + \epsilon_i,
\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i = Y_{0i} - E[Y_{0i}]\)&lt;/span&gt;, the random part of &lt;span class=&#34;math inline&#34;&gt;\(Y_{0i}\)&lt;/span&gt;. Evaluating this with both treatment statuses gives us:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
 E[Y_i|D_i = 1] = \alpha + \beta + E[\epsilon_i|D_i = 1],\\
 E[Y_i|D_i = 0] = \alpha + E[\epsilon_i|D_i = 0]
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The difference between these two equations reveals:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
E[Y_i|D_i = 1] - E[Y_i|D_i = 0] = \beta + (E[\epsilon_i|D_i = 1] - E[\epsilon_i|D_i = 0])
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; in this regard can be seen as the treatment effect and the rest of the statement is the selection bias. More specifically, we can summarize the selection bias as the correlation between the error term &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; and the binary variable for treatment, &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If you have any experience with regression, you should know that it is seldom the case that the treatment dummy is used alone. Generally you’d include various fixed effects for demographics, location, etc. to help account for variation in &lt;span class=&#34;math inline&#34;&gt;\(Y_i\)&lt;/span&gt;. If these effects (or controls) are totally uncorrelated with the treatment assignment, then our estimate for &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; will be unaffected whether they are included or not. We include these controls in order to achieve more accurate estimates of effect size. When we are able to reduce the residual variance with extra controls, the standard errors of the estimates go down, giving us tighter confidence intervals and more specific estimates of the true effect.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Music Artist Recommendation with Implicit Feedback Data</title>
      <link>/willsmorgan.github.io/project/music-artist-recommendation-with-implicit-feedback-data/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/project/music-artist-recommendation-with-implicit-feedback-data/</guid>
      <description>&lt;div id=&#34;motivation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Motivation&lt;/h3&gt;
&lt;p&gt;Recommender systems are a surprisingly large part of lives. As consumers we’re faced with endless choices for music, clothing, etc. and it can often lead to what psychologists call &lt;a href=&#34;https://en.wikipedia.org/wiki/Decision_fatigue&#34;&gt;Decision Fatigue&lt;/a&gt;. In a sentence, it is the idea that the opportunity cost of considering all items on a menu becomes so high that the quality of decision-making drops. Naturally, retailers and media providers are incentivized to limit the amount of items they show to a consumer, so the question of ranking item importance becomes highly relevant.&lt;/p&gt;
&lt;p&gt;There are many ways to build a recommender system, but there are two general categorizations of these methods, defined mostly by the type of data that is used. First, there is &lt;em&gt;content-based&lt;/em&gt; recommendation. This type of system profiles users and items and makes recommendations based on common characteristics. Data used in this sort of design can include survey responses, demographic information, and other personal information. The item-profile data is a bit more dependent on the specific domain. Music for instance, can be profiled by the year of publication, tempo, or volume. The second categroy is called &lt;em&gt;collaborative filtering&lt;/em&gt; and will be the type of model we employ in this project. These techniques rely on data describing user-item interactions. That is, predictions are made based on users’ past song listens, purchases, or rating. A really famous example of collaborative filtering being used in real life is the model that won the a competition hosted by Netflix in 2008. The paper can be found &lt;a href=&#34;https://www.netflixprize.com/assets/GrandPrize2009_BPC_BellKor.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The data set used in the Netflix competition was unique in that it provided a lot of detail not usually found in collaborative feedback data sets. The data itself was essentially a really large matrix with individual users as rows, movies as the columns, and user ratings occupying the cells. What makes this data special is that to be included in set, users had to voluntarily rate the movies they watched. If you’re anything like me, you might realize how this could easily suffer from selection bias. I seldom have any interest in rating movies after watching them, so you could easily argue that my “type” of user would be highly underrepresented in the data. Along with this issue, another major problem with this kind of data is that it can be prohibitively expensive to collect. Instead, a much simpler and cheaper way of collecting feedback data is to observe user-item interactions. These interactions can be defined in a number of ways but it is commonly thought of a user accessing an item in a catalogue. These type of data are known as &lt;em&gt;implicit feedback&lt;/em&gt; data as opposed to the &lt;em&gt;explicit feedback&lt;/em&gt; of the Netflix challenge. Implicit feedback data is not without its problems (see my paper for a lengthier discussion), but it is an excellent starting point for a firm constructing it’s first recommender system. Because of this, many techniques using this data have been developd in recent years, most notably the&lt;br /&gt;
&lt;a href=&#34;http://yifanhu.net/PUB/cf.pdf&#34;&gt;&lt;em&gt;Alternating Least Squares&lt;/em&gt;&lt;/a&gt; model developed by Yifan Hu.&lt;/p&gt;
&lt;p&gt;The remainder of this project will continue as follows: I’ll spend some time describing the model itself, discuss how to evaluate it, and finally implement it on the Last.fm artist recommendation data set.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Small disclaimer&lt;/strong&gt;: this project was done in place of a final exam for a graduate machine learning course I took from Dr. Robert McCulloch at ASU. A formal paper is saved &lt;a href=&#34;https://github.com/willsmorgan/Recommender-Systems-using-W-ALS/blob/master/W-ALS%20Final.pdf&#34;&gt;here&lt;/a&gt; that I recommend reading for a much more thorough description of my work.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-definitions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model Definitions&lt;/h3&gt;
&lt;p&gt;We first define &lt;span class=&#34;math inline&#34;&gt;\(R = (r_{ui}) \in \mathbb{R}^{m x n}\)&lt;/span&gt; to be the user-item interaction matrix, where each entry &lt;span class=&#34;math inline&#34;&gt;\(r_{ui}\)&lt;/span&gt; denotes the rating of item &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; made by user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt;. In this regard, we have &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; users rating &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; items. The general goal of the model is to decompose &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; into two lower-rank matrices representing latent user and item factors that abstractly define individual user and item characteristics. Formally, we aim to find a vector &lt;span class=&#34;math inline&#34;&gt;\(x_u \in \mathbb{R}^f\)&lt;/span&gt; for each user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; and one for each item &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(y_i \in \mathbb{R}^f\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; is the number of latent factors we wish to estimate.&lt;/p&gt;
&lt;p&gt;Our model assumes a standard &lt;em&gt;Loss + Penalty&lt;/em&gt; objective function. In this situation, we use squared error and and L2 penalty on the parameters &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{x}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{y}\)&lt;/span&gt;. The model is thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\min_{x,y} \sum_{u, i} (r_{ui} - x_{u}^{T}y_{i})^2 + \lambda ( \vert{x_u}\vert^2 + \vert{y_i}\vert^2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Notice that we take the cross product of &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{x}^{T}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{y}\)&lt;/span&gt; to create the estimated user-item interaction matrix. The loss is then calculated elementwise by summing the squared difference between the actual and predicted ratings.&lt;/p&gt;
&lt;p&gt;In explicit feedback settings the ratings are directly observed so we could directly begin solving this problem. By definition implicit feedback data do not report these ratings, so Hu cleverly adjusts the observations to reflect our confidence in a user’s preference toward a particular item. To this end, we introduce two new sets of variables &lt;span class=&#34;math inline&#34;&gt;\(p_{ui}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c_{ui}\)&lt;/span&gt; perceived preference and our confidence in that guess, respectively. &lt;span class=&#34;math inline&#34;&gt;\(p_{ui}\)&lt;/span&gt; are simply binary values for having detected any interaction with a given item. That is,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
  p_{ui} =
    \begin{cases}
      1 &amp;amp; r_{ui} &amp;gt; 0\\
      0 &amp;amp; r_{ui} = 0
    \end{cases}       
\end{equation}
\]&lt;/span&gt; We have some latitude in deciding exactly how to define &lt;span class=&#34;math inline&#34;&gt;\(c_{ui}\)&lt;/span&gt;. It is clear that &lt;span class=&#34;math inline&#34;&gt;\(c_{ui}\)&lt;/span&gt; will be a nonnegative function increasing in &lt;span class=&#34;math inline&#34;&gt;\(r_{ui}\)&lt;/span&gt;, so the majority of the decision lies in the rate at which our confidence increases. Hu suggests two recommendations:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
 c_{ui} = 1 + \alpha r_{ui},\\
 c_{ui} = 1 + \alpha \text{log}(1 + \frac{r_{ui}}{\epsilon})
\end{eqnarray}
\]&lt;/span&gt; The choice is left up to the practitioner, but no matter the choice &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; are determined by cross-validation. Once we settle on something for &lt;span class=&#34;math inline&#34;&gt;\(c_{ui}\)&lt;/span&gt;, we can formalize the objective function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation}
    \min_{x,y} \sum_{u,i} c_{ui}(p_{ui} - x_{u}^T y_i)^2 + \lambda(\sum_u \vert{x_u}\vert^2 + \sum_{i} \vert{y_i}\vert^2)
\end{equation}
\]&lt;/span&gt; Because we are optimizing over two variables the loss function is not convex, making this problem a whole lot more difficult to solve. To get around this, we hold one argument fixed and solve for the other iteratively. More specifically, when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is held constant the function is quadratic in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; and we can thus find a global minimum. The algorithm iterates back and forth betwen the two variables until a stopping criteria is met, hence the name “Alternating Least Squares”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluating-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Evaluating the Model&lt;/h3&gt;
&lt;p&gt;Once the user and item factors have been found we can predict an individual’s preference toward any item by calculating &lt;span class=&#34;math inline&#34;&gt;\(\hat{p}_{ui} = \hat{x}^T_{u} \hat{y}_i\)&lt;/span&gt;. Recommendations are then made by selecting the top &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; items for which &lt;span class=&#34;math inline&#34;&gt;\(\hat{p}_{ui}\)&lt;/span&gt; is greatest.&lt;/p&gt;
&lt;p&gt;This prediction methodology lends itself to the Mean Average Precision (MAP) and Normal Discounted Cumulative Gain (NDCG) evaluation metrics. MAP and NDCG are computed after the practitioner decides how many items to recommend (&lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt;) and so these metrics are usually referred to as &lt;a href=&#34;mailto:MAP@K&#34;&gt;MAP@K&lt;/a&gt; and &lt;a href=&#34;mailto:NDCG@K&#34;&gt;NDCG@K&lt;/a&gt;. Both metrics have values between 0 and 1, allowing us to compare performance across models with different hyperparameters.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto:MAP@K&#34;&gt;MAP@K&lt;/a&gt; measures the precision of K recommendations using binary relevance - whether or not the item is relevant to the user. By classifying each item recommendation as 1 or 0 we can measure the average precision of a recommendation to a particular user by averaging the 1s divided by their ranking in the list. MAP then averages that value across all users. For example, if a user is recommended five items and the first two and last two are relevant, we have the sequence &lt;span class=&#34;math inline&#34;&gt;\(\{1, 1, 0, 1, 1\}\)&lt;/span&gt;. Relative to their ranking in this list, that sequence becomes &lt;span class=&#34;math inline&#34;&gt;\(\{\frac{1}{1}, \frac{1}{2}, 0, \frac{3}{4}, \frac{4}{5}\}\)&lt;/span&gt;, and averaging the non-zero values gives an average precision score of .7625.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto:NDCG@K&#34;&gt;NDCG@K&lt;/a&gt; is slightly more complex in that it allows for real-valued item relevances and discounting for items occurring later in the list, but the general idea is the same.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;implementing-the-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Implementing the Model&lt;/h3&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Packages&lt;/h4&gt;
&lt;p&gt;Along with the standard data wrangling packages like &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;data.table&lt;/code&gt;, &lt;code&gt;rsparse&lt;/code&gt; from &lt;a href=&#34;https://github.com/dselivanov/rsparse&#34;&gt;Dmitriy Selivanov&lt;/a&gt; contains the algorithm used to solve the model. &lt;code&gt;Matrix&lt;/code&gt; is also used for creation and manipulation of sparse matrices.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-description&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Data Description&lt;/h4&gt;
&lt;p&gt;This analysis will be done using the publicly available Last.fm Music Recommendation Dataset. This data contains (user, artist, plays) tuples for approximately 360,000 users and 186,000 artists collected from the Last.fm API. With this data our task will be to recommend artists to individual users, and entries in our user-item interaction matrix &lt;span class=&#34;math inline&#34;&gt;\(r_{ui}\)&lt;/span&gt; will be the number of times a user &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; has listened to artist &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. Although we have around 17.5 million (user, artist, plays) observations, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; will still be approximately 99.97% sparse.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cleaning-and-preparation&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Cleaning and Preparation&lt;/h4&gt;
&lt;p&gt;For the sake of interpretation and more easily keeping track of things, I chose to replace all the user and item ids with unique integer-valued ids. Initially, they come as long nonsensical character strings so this was just an easy way to standardize the naming.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Use integer-valued ids for users and items
user_encoding &amp;lt;-  raw_data %&amp;gt;%
  distinct(user_id) %&amp;gt;%
  mutate(uid = row_number())
  
item_encoding &amp;lt;- raw_data %&amp;gt;%
  distinct(artist_id) %&amp;gt;%
  mutate(iid = row_number())

dt &amp;lt;-  raw_data %&amp;gt;%
  select(-artist_name) %&amp;gt;%
  inner_join(user_encoding, by = &amp;#39;user_id&amp;#39;) %&amp;gt;%
  inner_join(item_encoding, by = &amp;#39;artist_id&amp;#39;)

rm(raw_data)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;training-and-tuning&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Training and Tuning&lt;/h4&gt;
&lt;p&gt;Implicit feedback datasets often have some sort of time dimension separating two or more periods of observed activity. This is incredibly useful as it creates a natural testing dataset on which to evaluate models. Unfortunately, this dataset lacks this so we have to artificially create our own test set from the original. Briefly put, we select 30,000 users to be part of our test set and of the 30,000 users we randomly select 50% of their non-zero observations to use as a historical/future split. The validation strategy is as follows:&lt;/p&gt;

&lt;p&gt;In R, it ends up looking like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define our model matrix
X = sparseMatrix(i = dt$uid, j = dt$iid, x = dt$number_plays, 
                 dimnames = list(user_encoding$user_id, item_encoding$artist_name))

# Sample 30K users
n_test &amp;lt;- 30000L
test_uid &amp;lt;- sample(nrow(user_encoding), n_test)

# Split into train/test
X_train &amp;lt;-  X[-test_uid, ]
X_test &amp;lt;-  X[test_uid, ]

rm(X)

# Split our test set into &amp;quot;history&amp;quot; or &amp;quot;future&amp;quot;
temp = as(X_test, &amp;quot;TsparseMatrix&amp;quot;)
temp = data.table(i = temp@i, j = temp@j, x = temp@x) 

# Sample 50% of each user&amp;#39;s history
temp &amp;lt;- temp %&amp;gt;%
  group_by(i) %&amp;gt;%
  mutate(ct = length(j),
         history = 
           sample(c(TRUE, FALSE), ct, replace = TRUE, prob = c(.5, .5))) %&amp;gt;%
  select(-ct)

# Split test based on 50% sample
X_test_history &amp;lt;- temp %&amp;gt;% filter(history == TRUE)
X_test_future &amp;lt;- temp %&amp;gt;% filter(history == FALSE)

rm(temp)

# Convert them back to sparse matrices
X_test_history &amp;lt;- sparseMatrix(i = X_test_history$i,
                               j = X_test_history$j,
                               x = X_test_history$x,
                               dims = dim(X_test),
                               dimnames = dimnames(X_test),
                               index1 = FALSE)

X_test_future &amp;lt;- sparseMatrix(i = X_test_future$i,
                              j = X_test_future$j,
                              x = X_test_future$x,
                              dims = dim(X_test),
                              dimnames = dimnames(X_test),
                              index1 = FALSE)

# Clean up
rm(user_encoding, item_encoding, n_test, test_uid, dt)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;transform-observations-to-confidence-values&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Transform Observations to Confidence values&lt;/h4&gt;
&lt;p&gt;Before initializing, we define the two confidence functions mentioned above. Notice that we leave the “future” observations of the test set untouched. This is done so we can actually make predictions on the set and evaluate the model. For the sake of time, we only use the linear confidence function with &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define confidence functions and create matrices
log_conf &amp;lt;-  function(x, alpha, epsilon){
  x_confidence &amp;lt;-  x
  stopifnot(inherits(x, &amp;quot;sparseMatrix&amp;quot;))
  x_confidence@x = 1 + alpha * log(1 + (x@x / epsilon))
  return(x_confidence)
}

lin_conf &amp;lt;- function(x, alpha) {
  x_confidence &amp;lt;- x
  stopifnot(inherits(x, &amp;quot;sparseMatrix&amp;quot;))
  x_confidence@x = 1 + alpha * x@x
  return(x_confidence)
}

alpha &amp;lt;- .1
X_train_conf &amp;lt;- lin_conf(X_train, alpha)
X_test_history_conf &amp;lt;- lin_conf(X_test_history, alpha)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;initialize&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Initialize&lt;/h4&gt;
&lt;p&gt;This part is relatively simple - we simply invoke &lt;code&gt;rsparse::WRMF$new&lt;/code&gt; and select the rank of the latent factor matrices we want to estimate, and then select the metrics for scoring. In this example, we use &lt;a href=&#34;mailto:MAP@10&#34;&gt;MAP@10&lt;/a&gt; and &lt;a href=&#34;mailto:NDCG@10&#34;&gt;NDCG@10&lt;/a&gt;. Again, in the interest of time we only choose 10 but this can easily be turned into a loop to evaluate models with varying numbers of factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Initialize a model
model &amp;lt;- WRMF$new(rank = 10L)

# Add scoring metrics
model$add_scorers(x_train = X_test_history_conf, x_cv = X_test_future,
                  list(&amp;quot;map10&amp;quot; = &amp;quot;map@10&amp;quot;, &amp;quot;ndcg-10&amp;quot; = &amp;quot;ndcg@10&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;train-the-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Train the Model&lt;/h4&gt;
&lt;p&gt;Now that everything is set up, we can execute the &lt;code&gt;fit_transform&lt;/code&gt; method and calculate the latent factors. In &lt;code&gt;rsparse&lt;/code&gt;, these are called the &lt;em&gt;user_embeddings&lt;/em&gt; and the &lt;em&gt;item_embeddings&lt;/em&gt;. Once the factors are estimated, we can predict a new user’s user-feature vector by simply iterating one more time (using our previous solution for &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# User embeddings
user_embeddings &amp;lt;- model$fit_transform(X_train_conf)

# Item embeddings 
item_embeddings &amp;lt;-  model$components

# Make a prediction for a new user
new_user_embeddings &amp;lt;- model$transform(X_test_history_conf)
new_user_1 &amp;lt;-  X_test_history_conf[1:1, , drop = FALSE]

new_user_predictions &amp;lt;- model$predict(new_user_1, k = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tune-the-model&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Tune the Model&lt;/h4&gt;
&lt;p&gt;In most other scenarios, we’d want to specify a grid of possible hyperparameters to find the best-performing ones for our model. This isn’t a huge concern for this toy example, but here is a glance at the CV scheme I used for my paper:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Convergence parameters
n_iter_max = 10L
convergence_tol = .01

# Hyperparameters to test
grid = expand.grid(alpha = c(.01, .1, 1),
                   rank = c(8, 16, 32, 40),
                   lambda = c(.01, .1, 1, 10))

# Empty vector to throw results into
scores &amp;lt;-  vector(&amp;quot;list&amp;quot;, nrow(grid))

# Begin tuning
for (k in seq_len(nrow(grid))){
  # Define parameters
  alpha = grid$alpha[[k]]
  rank = grid$rank[[k]]
  lambda = grid$lambda[[k]]
  
  # Initialize
  model &amp;lt;- WRMF$new(rank = rank)
  
  # Conf. matrices
  X_train_conf&amp;lt;- lin_conf(X_train, alpha)
  X_test_history_conf &amp;lt;- lin_conf(X_test_history, alpha)
  
  # Scoring metrics
  model$add_scorers(x_train = X_test_history_conf,
                    x_cv = X_test_future,
                    list(&amp;quot;map10&amp;quot; = &amp;quot;map@10&amp;quot;, &amp;quot;ndcg-10&amp;quot; = &amp;quot;ndcg@10&amp;quot;))
  
  # Fit
  fit &amp;lt;-  model$fit_transform(X_train_conf, n_iter = n_iter_max,
                              convergence_tol = convergence_tol)

  # Extract score
  score &amp;lt;-  attr(fit, &amp;quot;trace&amp;quot;)
  
  score$alpha = alpha
  score$lambda = lambda
  score$rank = rank
  
  # Add to list
  scores[[k]] &amp;lt;-  score
  
  # Clean up
  rm(alpha, rank, lambda, model, score)
}

cv_results &amp;lt;-  bind_rows(scores) %&amp;gt;%
  group_by(alpha, lambda, rank, scorer) %&amp;gt;%
  arrange(iter) %&amp;gt;%
  filter(row_number() == n()) %&amp;gt;%
  select(-iter) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;further-readings-and-references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Further readings and references&lt;/h3&gt;
&lt;p&gt;This was work was inspired by a lot of various blog posts and really interesting papers I found while learning about recommendation systems. In particular, &lt;a href=&#34;http://dsnotes.com/post/2017-06-28-matrix-factorization-for-recommender-systems-part-2/&#34;&gt;Dmitriy Selivanov’s&lt;/a&gt; post on implicit matrix factorization helped me with a large chunk of the code used to run the model. Ben Frederickson has two amazing posts &lt;a href=&#34;http://www.benfrederickson.com/matrix-factorization/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://www.benfrederickson.com/fast-implicit-matrix-factorization/&#34;&gt;here&lt;/a&gt; detailing his implementation of ALS in python, and Will Kirwin from Activision Games describes &lt;a href=&#34;http://activisiongamescience.github.io/2016/01/11/Implicit-Recommender-Systems-Biased-Matrix-Factorization/&#34;&gt;here&lt;/a&gt; ways to account for user and item biases.&lt;/p&gt;
&lt;p&gt;There are many other sources that have helped me with accomplish this project and for a complete list of citations please reference my paper &lt;a href=&#34;https://github.com/willsmorgan/Recommender-Systems-using-W-ALS/blob/master/W-ALS%20Final.pdf&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Book Discussion - Mostly Harmless Econometrics: Chapter 1</title>
      <link>/willsmorgan.github.io/post/book-discussion-mostly-harmless-econometrics-chapter-1/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/book-discussion-mostly-harmless-econometrics-chapter-1/</guid>
      <description>

&lt;h4 id=&#34;motivation&#34;&gt;Motivation&lt;/h4&gt;

&lt;p&gt;This will be part of a series of posts I am writing to help bring my chops on causal
inference up to par. Since I have not taken a formal course on the subject and I won&amp;rsquo;t be
able to for some time, self-study is my only option. Fortunately I&amp;rsquo;ve been recommended
quite a few resources from my instructors, one of which being
&lt;strong&gt;Mostly Harmless Econometrics&lt;/strong&gt; by Joshua D. Angrist &amp;amp; Jorn-Steffen Pischke,
econometricians at MIT and LSE respectively.&lt;/p&gt;

&lt;p&gt;This and the next handful of posts will be discussions about topics covered throughout
the book, including short summaries, descriptions of my understanding of the concepts,
and potential applications to my own work.&lt;/p&gt;

&lt;h4 id=&#34;chapter-1-questions-about-questions&#34;&gt;Chapter 1: Questions about &lt;em&gt;Questions&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;At the Action Lab there is practically an immeasurable variety of data available
to us researchers. We have student data, institutional data, clickstream data,
and all other sorts of data that has been collected for years and years. When I was
dumped into this massive environment as a fresh student worker I was
hopping around from one thing to the next, searching for ways to implement everything
I had learned in class and hoping to find great insights everywhere I went. As any
experienced researcher would expect, this ended up wasting a lot of time. I wrote
tons of cleaning and modeling scripts for projects that eventually were
thrown into the &amp;ldquo;revisit this&amp;rdquo; folder of my hard drive, never to be touched again.&lt;/p&gt;

&lt;p&gt;The lack of direction in my research was keeping me from accomplishing anything. I was constantly
getting ahead of myself, imagining the shiny new models I could implement and the fantastic
results I could expect instead of nailing down a specific research agenda. A much more pragmatic
approach would have been to follow the strategy offered by Angrist and Pischke in their opening
chapter, &lt;strong&gt;Questions about Questions&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The FAQs as they call them, are the four research questions econometricians
should ask themselves before embarking on a new project:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;What is the causal relationship of interest?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is the ideal experiment that would identify this causal effect?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is the identification strategy?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is the mode of statistical inference?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first question is pretty straightforward, or at least it should be - it
is the foundation of the entire project. Nonetheless, it is important
to explicitly identify the relationship you want to investigate. Doing so will be helpful in several ways
as the project matures. First, it will help give you a sense
of your data necessities. If you are interested in changes in employment outcomes
as a result of successfully completing MOOCs, you should be considering
the types of outcomes that are observable and their availability to the public.
Second, knowing the type of relationship you&amp;rsquo;re trying
to measure will inform your methodology. A relationship that is temporal in nature
will likely call for some sort of time series model, or maybe the effect
only manifests in extreme scenarios, in which case subsampling might be of interest.&lt;/p&gt;

&lt;p&gt;Our second question is slightly more abstract than the first but still important in
designing the overall agenda. In the event that you end up with a limitless budget and no higher authority questioning
your ethics, what&amp;rsquo;d be the best scenario for observing the effect you are interested in?
Your answer doesn&amp;rsquo;t have to be feasible, but it does have to be realistic. The point of this
question is to force you to consider all possible mechanisms to be changed or held constant in order to observe
the effect you&amp;rsquo;re after. The secondary purpose of this question is to help you reveal potential
flaws with the overall goal of the research. Questions that cannot be answered
by any sort of experimental design are what Angrist and Pischke call FUQ&amp;rsquo;d:
Fundamentally Unanswered Questions.&lt;/p&gt;

&lt;p&gt;Our two final questions are concerned with the specific data and methodological needs
to carry out a study. Often it is the case in economics (and social sciences more generally)
that experimentation is not feasible because of cost or ethical concerns. Observational data
then becomes the stand-in for data generated by a randomized trial, so it is crucial for
researchers to understand how to use that data in order to simulate a real experiment.
This technique, as the authors define it, is the &lt;em&gt;identification strategy&lt;/em&gt;. The mode of statistical
inference is closely related to a researcher&amp;rsquo;s identification strategy. It defines the population
of interest, the type of sample that is collected, and the various modeling assumptions that
have to be made in order to extract reasonable, well-constructed results. This will be the most
technically demanding portion of the project and the integrity of the results will rely almost
entirely on the correct execution of your statistics.&lt;/p&gt;

&lt;p&gt;The answers to these FAQs should outline very clearly a researcher&amp;rsquo;s entire project agenda.
Without answering these, a straightforward project can quickly derail and turn into
a sloppy mess of misguided intentions and no clear end. In any case, this opening chapter
of &lt;em&gt;Mostly Harmless Econometrics&lt;/em&gt; has made me reconsider how I approach the research I want
to conduct and will hopefully make me a more pragmatic and efficacious student of economics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parallelizing Random Forests in R</title>
      <link>/willsmorgan.github.io/post/parallelizing-random-forests-in-r/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/willsmorgan.github.io/post/parallelizing-random-forests-in-r/</guid>
      <description>&lt;p&gt;Recently I’ve been working on a project with the goal of understanding how students choose between course modalities (online or in-person). My goal so far has been to test a handful of models to come up with the most accurate way of predicting the likelihood that a student will take a course online. Hopefully, this best-performing model would offer some interpretability so that I can see which variables offer the most predictive power.&lt;/p&gt;
&lt;p&gt;In working through this problem it has become necessary for me to take advantage of parallel processing so I can actually get results in a reasonable amount of time. &lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/index.html&#34;&gt;&lt;code&gt;glmnet&lt;/code&gt;&lt;/a&gt; offers in-house parallel processing, so for penalized regression it has been a breeze. On the other hand, I haven’t found a native implementation in &lt;a href=&#34;https://cran.r-project.org/package=randomForest&#34;&gt;&lt;code&gt;randomForest&lt;/code&gt;&lt;/a&gt; so I thought it might be a good exercise to create one myself and make a post about it in case there are others that run into the same problem.&lt;/p&gt;
&lt;p&gt;I use several packages to accomplish this task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;doParallel&lt;/code&gt;, &lt;code&gt;foreach&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;The workhorse behind the parallel processing&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;caret&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Not explicitly called on in this example, but I do use it in my other work to define folds for cross-validation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;randomForest&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Used for creating the trees&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is only a little more than 50 lines of code in the example, but there is a good amount to dissect. First, it should be noted that the size of the tree must be specified a priori - the main goal is to get an estimate of the out-of-sample error for a particular forest size (i.e. a specific hyperparameter value). The function starts by iterating through each of the K folds of your data. For a given fold, the tree-growing is done in ten separate groups and then combined. In other words, for a random forest with 100 trees, we grow ten forests of ten trees and combine them using &lt;code&gt;randomForest::combine&lt;/code&gt; (this decision about ten groups is completely arbitrary, I just assumed that any forest size I was going to test would be divisible by ten). This function is absolutely critical and is the key reason we can use &lt;code&gt;%dopar%&lt;/code&gt; here. Once the random forest is put back together, we estimate the out-of-sample error and move on to the next fold. Finally, the results are averaged across all K folds and the function spits out a data frame detailing the number of trees that were grown and the misclassification rate.&lt;/p&gt;
&lt;p&gt;This function isn’t perfect, but it certainly does the trick. It’d be nice to include some other forms of error on top of the misclassification rate and allow for many forest sizes to be tested. For now, I’ll keep this in my back pocket and robustify it in the future.&lt;/p&gt;
&lt;p&gt;UPDATE (7.31.18):&lt;/p&gt;
&lt;p&gt;I was running this on around ~600K observations for 15 different tree sizes and for some reason I was ending up a lot of “zombie” processes. I have no clue what was happening, but I’ve updated the function to be more programmatically sound to hopefully get rid of the problem.&lt;/p&gt;
&lt;p&gt;There is now a specific function (&lt;code&gt;parGrow&lt;/code&gt;) for parallel growth that will force the cluster to close. In addition, I’ve updated the functionality so that you can feed in a vector of tree sizes to test instead of just a single tree size. Finally, I’ve added the option for test set prediction so that everything can be run all within the single function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cvRF &amp;lt;- function(X_train, Y_train, folds, tree_sizes, X_test = NULL, Y_test = NULL, ncores = 10) {
  &amp;#39;
  Use foreach to parallelize RF tree growth for a specified number of trees and
  estimate OOB error using cross-validation
  
  Args:
  - X_train --&amp;gt; matrix of training predictors
  - Y_train --&amp;gt; vector/factor of training outcomes
  - ntrees --&amp;gt; number of trees to grow in forest
  - folds --&amp;gt; user-supplied vector of folds
  - X_test, Y_test ---&amp;gt; test set used for prediction
  
  Returns:
  - df with two columns:
  - num_trees
  - cv misclassification rate
  - test misclassiciation rate (if test set supplied)
  &amp;#39;
  # Define function to parallelize forest growth
  parGrow &amp;lt;- function(X, Y, tree_size) {
    
    # Search parent environment for ncores and initalize cluster
    if (ncores &amp;gt; 1) {
      cl &amp;lt;- makeCluster(ncores)
      registerDoParallel(cl)
      on.exit(stopCluster(cl))
    }
    
    # Grow trees in parallel and combine into one
    rf &amp;lt;- foreach(ntree = rep(tree_size/10, 10),
                  .combine = randomForest::combine,
                  .multicombine = TRUE,
                  .inorder = FALSE,
                  .packages = &amp;#39;randomForest&amp;#39;) %dopar% {
                    
                    # Grow indvl tree on the k-1 folds
                    randomForest(
                      x = X,
                      y = Y,
                      ntree = ntree,
                      mtry = sqrt(dim(X)[2])
                    )
                  }
    
    # Return an RF object
    rf
  }
  
  # Define function to evaluate specific fold
  evalFold &amp;lt;- function(fold) {
    
    # Train forest
    forest &amp;lt;- parGrow(X = X_train[folds != fold, ],
                      Y = Y_train[folds != fold],
                      tree_size = tree_size)
    
    # Evaluate on OOS fold
    preds &amp;lt;- predict(forest,
                     X_train[folds == fold, ],
                     type = &amp;#39;response&amp;#39;)
    
    # Return df of results
    data.frame(
      tree_size = tree_size,
      cv_misclass = 1 - mean(preds == Y_train[folds == fold]),
      fold = fold
    )
    
  }
  
  # Define function to run through all folds  
  runCV &amp;lt;- function() {
    
    # Train and evaluate each fold
    cv_result &amp;lt;- foreach(fold = 1:max(folds),
                         .combine = bind_rows,
                         .multicombine = TRUE,
                         .inorder = FALSE) %do% {
                           
                           # Print status
                           cat(&amp;quot;Fold&amp;quot;, fold, &amp;quot;of&amp;quot;, max(folds), &amp;quot;\n&amp;quot;)
                           
                           # Run evaluation tool
                           evalFold(fold)
                         }
    
    # Summarise across folds
    cv_result %&amp;lt;&amp;gt;%
      group_by(tree_size) %&amp;gt;%
      summarise_at(vars(cv_misclass), mean)
    
    # Return cv_results
    cv_result
  }
  
  # Run through vector of tree sizes
  result &amp;lt;- foreach(i = seq_along(tree_sizes),
                    .combine = bind_rows,
                    .multicombine = TRUE,
                    .inorder = FALSE) %do% {
                      
                      cat(&amp;quot;Testing RF of size:&amp;quot;, tree_sizes[i], &amp;quot;\n&amp;quot;)
                      
                      # Establish tree size to test
                      tree_size &amp;lt;- tree_sizes[i]
                      
                      # Run CV for current tree size
                      cv_result &amp;lt;- runCV()
                      
                      # Find test error if supplied
                      if (!is.null(X_test) &amp;amp; !is.null(Y_test)) {
                        
                        # Grow on full training set
                        rf &amp;lt;- parGrow(X_train, Y_train, tree_size)
                        
                        # Predict
                        test_pred &amp;lt;- predict(rf, X_test, type = &amp;#39;response&amp;#39;)
                        test_misclass &amp;lt;- 1 - mean(test_pred == Y_test)
                        
                        # Attach result to existing df of results
                        cv_result$test_misclass &amp;lt;- test_misclass
                      }
                      
                      # Print result for row binding
                      cv_result
                    }
}&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
